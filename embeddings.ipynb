{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca090bd-50b7-4a3e-af37-7bd5457db3fa",
   "metadata": {},
   "source": [
    "# AI Builders Week 3 Homework\n",
    "## Resume matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e49da9-f9fb-4b8f-95a7-413206be72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://miguel-vila.github.io/resume_EN.pdf')\n",
    "response.raise_for_status()\n",
    "pdf_bytes = response.content\n",
    "resume = pymupdf.open(stream=pdf_bytes, filetype='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befea48c-96d1-440d-8e6d-9e547e1a14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MIGUEL VIL´A GONZ´ALEZ\\nmiguel-vila @ github\\nPROFESSIONAL EXPERIENCE\\nSenior Software Engineer\\nRemote - US East Coast Timezone\\nSiriusXM\\nNovember 2022 - Present\\n· Member of the API tooling team, part of the platform services enablement organization.\\n· Develop tooling using Smithy, an AWS DDL language, empowering teams to describe, implement, and consume\\ntheir services.\\n· Key projects include:\\n· Developed a system for describing which Smithy services are implemented and consumed by applications,\\nenabling package management and dependency tracing across the platform.\\n· Implemented compatibility checks to verify service changes against potential data processing breakages.\\n· Contributed to a team implementing semantic search using vector embeddings stored in OpenSearch.\\n· Set up infrastructure to ingest catalog data and generate embeddings using different models.\\n· Set up a client to query the different indexes using the embeddings.\\nLead Software Engineer ←Senior Software Engineer ←Software Engineer\\nUnited Kingdom\\nDisney (formerly Disney Streaming Services)\\nJanuary 2017 - October 2022\\n· Built and maintained Disney+ and ESPN+ streaming platforms as a member of various engineering teams,\\nutilizing Scala, Python, TypeScript, and AWS services.\\n· Developed and maintained commerce operation services, including subscription lifecycle management, collaborat-\\ning with cross-functional teams on feature delivery.\\n· Participated in the evolution, migration, and unification of the subscription system.\\n· Led a project migrating one of the subscription system’s clients to a next-generation version:\\n· Crafted technical proposals and guided decision-making.\\n· Collaborated with client teams through technical discussions to ensure thorough understanding of requirements\\nand edge cases.\\n· Conducted research to inform the implementation.\\n· Improved documentation to streamline onboarding.\\n· Decomposed project work into discrete, deliverable units.\\n· Other responsibilities and achievements included:\\n· Designed and proposed new components to enhance the subscription management system’s API and domain\\nevents, collaborating with engineers on design and behavior. Resulted in improved data quality for analytics\\nand increased visibility into the subscription lifecycle.\\n· Developed and maintained a component to detect subscription overlaps between partner-issued and existing user\\nsubscriptions, automatically applying pauses or discounts per business rules. This enhanced user experience\\nand reduced customer service costs.\\n· Onboarded new team members to the subscription team, providing domain primers and iteratively improving\\ninternal documentation.\\n· Authored multiple technical proposals, presenting various options, advocating for preferred solutions, and de-\\ncomposing them into actionable tasks for team execution.\\n· Proposed and implemented a change to test-subscription creation logic, removing reliance on naming conven-\\ntions. This enabled complex scenario testing for other teams, simplified test data identification and cleanup,\\nand reduced storage costs.\\n· Developed user authentication, account management, and profile management services, including multiple Scala-\\nbased microservices, as part of a separate team.\\n· Executed performance tests against these services to define appropriate scaling policies.\\n· Helped establish the infrastructure for multiple projects.\\nSoftware Engineer\\nColombia\\ns4n\\nJanuary 2013 - June 2016\\n\\n· Led a small engineering team, responsible for technical decision-making and mentoring new members on the tech\\nstack (Java, Scala, JavaScript).\\n· Developed enterprise software for diverse clients, primarily in the insurance sector, using Java, Scala, and\\nJavaScript.\\n· Developed a REST API using Scala for an international client in the United States.\\nTeaching Assistant for Design and Analysis of Algorithms\\nColombia\\nLos Andes University\\nAugust 2011 - May 2012\\n· Evaluated student homework and exams. Organized and delivered preparatory lectures for exams.\\nSoftware Engineer\\nColombia\\nCIACUA, Los Andes University\\nMarch 2011 - August 2011\\n· Participated in the software reengineering of an application used for the design and simulation of water distribution\\nsystems. Documented the design in UML and fixed bugs found in a version update.\\nEDUCATION\\nRecurse Center\\nAugust 2016 - November 2016\\nUnited States of America\\nCompleted a self-directed, project-based residency for programmers, focusing on deepening expertise outside core\\nspecializations. Developed projects focused on distributed systems, concurrency, and functional programming.\\nLos Andes University\\nJanuary 2009 - December 2012\\nColombia\\nBSc in Systems and Computing Engineering\\nCOMPLEMENTARY EDUCATION\\n· Senior Engineer to Lead: Grow and thrive in the role (via Maven), Completed 2025.\\n· Introduction to Corporate Finance, University of Pennsylvania (via Coursera), Completed 2024.\\n· Financial Markets (with Honors), Yale University (via Coursera), Completed 2021.\\nVOLUNTEERING\\nClimbing Clan\\nApril 2023 - October 2024\\nManchester, United Kingdom\\nActive member of a climbing community in Manchester. Volunteered periodically, teaching belaying techniques\\nand assisting with administrative tasks.\\nACHIEVEMENTS AND AWARDS\\n· “Quiero Estudiar” Scholarship.\\nAwarded full scholarship for undergraduate studies at Los Andes University\\n(October 2008).\\n· Qualified for the Latin American Regional International Collegiate Programming Contest (ICPC), 2011.\\n· Qualified for the Latin American Regional International Collegiate Programming Contest (ICPC), 2012.\\nTECHNICAL SKILLS\\nProgramming Languages\\n(in order of skill):\\nScala, Java, Python, Javascript, TypeScript.\\nInfrastructure:\\nMostly AWS. Cloudformation, CDK, DynamoDB, Kinesis, ECS, CloudWatch.\\nOPEN SOURCE SOFTWARE CONTRIBUTIONS\\n\\nOver the course of my career, I have contributed to numerous open-source projects. These contributions were\\noften driven by project requirements—fixing bugs or adding features necessary for my work. Below are some of\\nmy most notable contributions:\\n· scalaz #750: Added new functionality, applying learned functional programming concepts.\\n· zio-metrics #53: Improved the external API of a metrics library for enhanced usability.\\n· smithy-translate #42: Fixed a critical bug in a dependency function, addressing an edge case unknown to\\nmaintainers and restoring library utility.\\n· spotbugs #2988: Fixed a bug in the SpotBugs static analysis tool related to reference comparison linting,\\naddressing a common source of Java errors.\\n· smithy #2221: Extended OpenAPI conversion to correctly handle deprecated annotations.\\n· opensearch-java #1005 & opensearch-api-specification #304: Extended the OpenSearch Java client to\\nsupport text embeddings.\\n· opensearch-api-specification #324: Enhanced the OpenSearch API specification testing framework to allow\\nstep output chaining, enabling more complex test scenario execution.\\nSIDE PROJECTS\\nPersonal projects available at: miguel-vila.github.io/side-projects.html\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of pages:\", len(resume))\n",
    "resume_str = '\\n'.join([page.get_text() for page in resume])\n",
    "resume_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93400f5-5883-4b8d-abea-56b91576b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "openAI = OpenAI()\n",
    "\n",
    "job_posting_format=\"\"\"\n",
    "```\n",
    "# Title\n",
    "{{job title}}\n",
    "## Description\n",
    "{{general job description}}\n",
    "## Responsibilities\n",
    "{{responsibilities}}\n",
    "## Qualifications\n",
    "{{qualifications}}\n",
    "## Bonus qualifications\n",
    "{{bonus qualifications}}\n",
    "```\"\"\"\n",
    "\n",
    "fake_job_posting_response = openAI.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\n",
    "        f\"\"\"The following is a resume for a specific person.\n",
    "        From that resume create a job listing that would fit that person.\n",
    "        Don't \"overfit\": use the described experience but don't reproduce the CV.\n",
    "        You don't have to mention specific companies.\n",
    "        Only mention the most commonly mentioned technologies or the ones that appear first in lists.\n",
    "        Output in the following format:\n",
    "        {job_posting_format}:\n",
    "        {resume_str}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c74d882-d032-4b0e-9ee9-6174306834fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "# Title\n",
       "Senior Software Engineer - API Tooling & Integration\n",
       "\n",
       "## Description\n",
       "Join our dynamic team as a Senior Software Engineer focused on developing innovative API tooling. This role involves enhancing platform services with scalable solutions using cutting-edge technologies. You will collaborate across teams to implement and integrate services effectively, ensuring seamless functionality and optimized performance.\n",
       "\n",
       "## Responsibilities\n",
       "- Develop and maintain API tooling using Smithy and AWS services.\n",
       "- Implement compatibility checks and systems to enhance dependency management.\n",
       "- Contribute to semantic search features using OpenSearch and vector embeddings.\n",
       "- Lead technical projects, from crafting proposals to guiding cross-team discussions and decisions.\n",
       "- Enhance and oversee subscription management systems, including development of user authentication and account management services.\n",
       "- Mentor new team members and improve internal documentation.\n",
       "- Conduct performance tests and define scaling policies.\n",
       "- Collaborate on open-source projects to fix and enhance features.\n",
       "\n",
       "## Qualifications\n",
       "- Extensive experience in software engineering with a strong focus on API development.\n",
       "- Proficiency in Scala, Python, TypeScript, AWS, and cloud infrastructure.\n",
       "- Strong project management skills, with experience leading technical projects.\n",
       "- Ability to decompose complex projects into deliverable units.\n",
       "- Excellent communication skills for collaborating with cross-functional teams.\n",
       "\n",
       "## Bonus qualifications\n",
       "- Experience in developing and maintaining subscription management systems.\n",
       "- Contributions to open-source projects, especially in the areas of functional programming and static analysis.\n",
       "- Familiarity with semantic search technologies and vector embeddings.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "fake_job_posting = fake_job_posting_response.output[0].content[0].text\n",
    "display(Markdown(fake_job_posting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d18350-8fc6-44c9-a42c-7b935089e909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site</th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_url_direct</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>job_type</th>\n",
       "      <th>salary_source</th>\n",
       "      <th>...</th>\n",
       "      <th>company_addresses</th>\n",
       "      <th>company_num_employees</th>\n",
       "      <th>company_revenue</th>\n",
       "      <th>company_description</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience_range</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>company_reviews_count</th>\n",
       "      <th>vacancy_count</th>\n",
       "      <th>work_from_home_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in-764d02c34833d113</td>\n",
       "      <td>indeed</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=764d02c34833...</td>\n",
       "      <td>https://jobs.ashbyhq.com/yumaai/cdc8c768-e82b-...</td>\n",
       "      <td>AI Product Focused - Senior Fullstack / Rails ...</td>\n",
       "      <td>Yuma AI</td>\n",
       "      <td>Boston, MA, US</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>direct_data</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in-82e200b3b54e6886</td>\n",
       "      <td>indeed</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=82e200b3b54e...</td>\n",
       "      <td>https://jobs.ashbyhq.com/gallatin/b7ed9bbb-496...</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Gallatin</td>\n",
       "      <td>El Segundo, CA, US</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>direct_data</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in-c9747635cab5e167</td>\n",
       "      <td>indeed</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=c9747635cab5...</td>\n",
       "      <td>https://grnh.se/mwr1jefn2us</td>\n",
       "      <td>Staff Software Engineer, Growth Products</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>San Francisco, CA, US</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direct_data</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multiply your earnings when you drive with Lyf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in-07678b0399d77ed6</td>\n",
       "      <td>indeed</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=07678b0399d7...</td>\n",
       "      <td>https://grnh.se/e8e4gmqg2us</td>\n",
       "      <td>Staff Software Engineer, Growth Products</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>New York, NY, US</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direct_data</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multiply your earnings when you drive with Lyf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in-f89ce04ae801a7c3</td>\n",
       "      <td>indeed</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=f89ce04ae801...</td>\n",
       "      <td>https://grnh.se/nxoofj1z2us</td>\n",
       "      <td>Staff Software Engineer, Growth Products</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>Seattle, WA, US</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direct_data</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multiply your earnings when you drive with Lyf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id    site  \\\n",
       "0  in-764d02c34833d113  indeed   \n",
       "1  in-82e200b3b54e6886  indeed   \n",
       "2  in-c9747635cab5e167  indeed   \n",
       "3  in-07678b0399d77ed6  indeed   \n",
       "4  in-f89ce04ae801a7c3  indeed   \n",
       "\n",
       "                                             job_url  \\\n",
       "0  https://www.indeed.com/viewjob?jk=764d02c34833...   \n",
       "1  https://www.indeed.com/viewjob?jk=82e200b3b54e...   \n",
       "2  https://www.indeed.com/viewjob?jk=c9747635cab5...   \n",
       "3  https://www.indeed.com/viewjob?jk=07678b0399d7...   \n",
       "4  https://www.indeed.com/viewjob?jk=f89ce04ae801...   \n",
       "\n",
       "                                      job_url_direct  \\\n",
       "0  https://jobs.ashbyhq.com/yumaai/cdc8c768-e82b-...   \n",
       "1  https://jobs.ashbyhq.com/gallatin/b7ed9bbb-496...   \n",
       "2                        https://grnh.se/mwr1jefn2us   \n",
       "3                        https://grnh.se/e8e4gmqg2us   \n",
       "4                        https://grnh.se/nxoofj1z2us   \n",
       "\n",
       "                                               title   company  \\\n",
       "0  AI Product Focused - Senior Fullstack / Rails ...   Yuma AI   \n",
       "1                                    DevOps Engineer  Gallatin   \n",
       "2           Staff Software Engineer, Growth Products      Lyft   \n",
       "3           Staff Software Engineer, Growth Products      Lyft   \n",
       "4           Staff Software Engineer, Growth Products      Lyft   \n",
       "\n",
       "                location date_posted  job_type salary_source  ...  \\\n",
       "0         Boston, MA, US  2025-09-02  fulltime   direct_data  ...   \n",
       "1     El Segundo, CA, US  2025-09-02  fulltime   direct_data  ...   \n",
       "2  San Francisco, CA, US  2025-09-02       NaN   direct_data  ...   \n",
       "3       New York, NY, US  2025-09-02       NaN   direct_data  ...   \n",
       "4        Seattle, WA, US  2025-09-02       NaN   direct_data  ...   \n",
       "\n",
       "  company_addresses  company_num_employees  company_revenue  \\\n",
       "0               NaN                    NaN              NaN   \n",
       "1               NaN                    NaN              NaN   \n",
       "2               NaN                    NaN              NaN   \n",
       "3               NaN                    NaN              NaN   \n",
       "4               NaN                    NaN              NaN   \n",
       "\n",
       "                                 company_description  skills  \\\n",
       "0                                                NaN     NaN   \n",
       "1                                                NaN     NaN   \n",
       "2  Multiply your earnings when you drive with Lyf...     NaN   \n",
       "3  Multiply your earnings when you drive with Lyf...     NaN   \n",
       "4  Multiply your earnings when you drive with Lyf...     NaN   \n",
       "\n",
       "   experience_range  company_rating  company_reviews_count vacancy_count  \\\n",
       "0               NaN             NaN                    NaN           NaN   \n",
       "1               NaN             NaN                    NaN           NaN   \n",
       "2               NaN             NaN                    NaN           NaN   \n",
       "3               NaN             NaN                    NaN           NaN   \n",
       "4               NaN             NaN                    NaN           NaN   \n",
       "\n",
       "  work_from_home_type  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jobs = pd.read_csv('jobs.csv')\n",
    "\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94c538e9-8939-41e3-8686-6b753dfb4a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: 8 rows, ~8138 input tokens (max/row ~1386 at df index 6)\n",
      "Batch 1: 8 rows, ~8564 input tokens (max/row ~1513 at df index 15)\n",
      "Batch 2: 8 rows, ~6811 input tokens (max/row ~1283 at df index 20)\n",
      "Batch 3: 8 rows, ~8845 input tokens (max/row ~1422 at df index 24)\n",
      "Batch 4: 8 rows, ~9321 input tokens (max/row ~2030 at df index 37)\n",
      "Batch 5: 8 rows, ~10974 input tokens (max/row ~1826 at df index 40)\n",
      "Batch 6: 8 rows, ~8627 input tokens (max/row ~1611 at df index 48)\n",
      "Batch 7: 8 rows, ~8537 input tokens (max/row ~2060 at df index 61)\n",
      "Batch 8: 8 rows, ~8365 input tokens (max/row ~1970 at df index 64)\n",
      "Batch 9: 8 rows, ~8172 input tokens (max/row ~1830 at df index 78)\n",
      "Batch 10: 8 rows, ~10857 input tokens (max/row ~1626 at df index 82)\n",
      "Batch 11: 8 rows, ~8139 input tokens (max/row ~1493 at df index 88)\n",
      "Batch 12: 8 rows, ~7280 input tokens (max/row ~958 at df index 101)\n",
      "Batch 13: 8 rows, ~5941 input tokens (max/row ~943 at df index 105)\n",
      "Batch 14: 8 rows, ~6513 input tokens (max/row ~1064 at df index 118)\n",
      "Batch 15: 8 rows, ~5316 input tokens (max/row ~1014 at df index 122)\n",
      "Batch 16: 8 rows, ~6107 input tokens (max/row ~1218 at df index 133)\n",
      "Batch 17: 8 rows, ~7407 input tokens (max/row ~1557 at df index 139)\n",
      "Batch 18: 8 rows, ~10987 input tokens (max/row ~2146 at df index 149)\n",
      "Batch 19: 8 rows, ~9477 input tokens (max/row ~1695 at df index 153)\n",
      "Batch 20: 8 rows, ~9340 input tokens (max/row ~1265 at df index 162)\n",
      "Batch 21: 8 rows, ~8748 input tokens (max/row ~1693 at df index 169)\n",
      "Batch 22: 8 rows, ~11890 input tokens (max/row ~1589 at df index 183)\n",
      "Batch 23: 8 rows, ~11011 input tokens (max/row ~1589 at df index 184)\n",
      "Batch 24: 8 rows, ~10618 input tokens (max/row ~1475 at df index 195)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from math import ceil\n",
    "import tiktoken\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "\n",
    "def normalize_description_prompt(description: str) -> str:\n",
    "    return f\"\"\"\n",
    "        Take the following job posting description and format it in the following way:\n",
    "        {job_posting_format}\n",
    "        Apply it to the following job description:\n",
    "        {description}\n",
    "    \"\"\"\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "enc = tiktoken.encoding_for_model(gpt_model)\n",
    "\n",
    "batches=25\n",
    "n = len(jobs)\n",
    "q, r = divmod(n, batches)\n",
    "sizes = [q + 1] * r + [q] * (batches - r)\n",
    "start = 0\n",
    "for batch_num, size in enumerate(sizes):\n",
    "    if size == 0:\n",
    "        continue  # guard if batches > n\n",
    "    end = start + size\n",
    "    jsonl_path = f\"requests-{batch_num}.jsonl\"\n",
    "    batch_jobs = jobs.iloc[start:end]\n",
    "    batch_tokens = 0\n",
    "    max_row_tokens, max_row_idx = 0, None\n",
    "    with open(jsonl_path, \"w\") as f:\n",
    "        for i, row in batch_jobs.iterrows():\n",
    "            custom_id = f\"row-{i}\"\n",
    "            prompt = normalize_description_prompt(row['description'])\n",
    "            body = {\n",
    "                \"model\": gpt_model,\n",
    "                \"input\": prompt\n",
    "            }\n",
    "            n_tokens = len(enc.encode(prompt))\n",
    "            batch_tokens += n_tokens\n",
    "            if n_tokens > max_row_tokens:\n",
    "                max_row_tokens, max_row_idx = n_tokens, i\n",
    "            f.write(json.dumps({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/responses\",\n",
    "                \"body\": body\n",
    "            }) + \"\\n\")\n",
    "    print(\n",
    "        f\"Batch {batch_num}: {size} rows, ~{batch_tokens} input tokens \"\n",
    "        f\"(max/row ~{max_row_tokens} at df index {max_row_idx})\"\n",
    "    )\n",
    "    start = end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "651e16ae-09e5-44c0-a3a2-6416248dfb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active batches:\n",
      "(none)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def list_active_batches(statuses=(\"validating\",\"in_progress\",\"queued\",\"running\",\"finalizing\")):\n",
    "    print(\"Active batches:\")\n",
    "    found = False\n",
    "    for b in openAI.batches.list().data:  # paginated; adjust if you have many\n",
    "        if b.status in statuses:\n",
    "            found = True\n",
    "            print(f\"- {b.id}  status={b.status}  created_at={b.created_at}  endpoint={b.endpoint}\")\n",
    "    if not found:\n",
    "        print(\"(none)\")\n",
    "\n",
    "def cancel_batch(batch_id: str):\n",
    "    print(f\"Cancelling {batch_id} ...\")\n",
    "    openAI.batches.cancel(batch_id)\n",
    "\n",
    "list_active_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc22f9-2356-4d62-9114-429d68462a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for batch: 0. Last status: validating. progress=0.0%\n",
      "waiting for batch: 0. Last status: in_progress. progress=0.0%\n",
      "waiting for batch: 0. Last status: in_progress. progress=0.0%\n"
     ]
    }
   ],
   "source": [
    "unified_results = {}\n",
    "import time\n",
    "\n",
    "for batch_num in range(batches):\n",
    "    upload = openAI.files.create(file=open(f\"requests-{batch_num}.jsonl\", \"rb\"), purpose=\"batch\")\n",
    "    batch = openAI.batches.create(\n",
    "        input_file_id=upload.id,\n",
    "        endpoint=\"/v1/responses\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "    status = openAI.batches.retrieve(batch.id)\n",
    "    while status.status in (\"validating\", \"in_progress\", \"running\", \"queued\"):\n",
    "        time.sleep(10)\n",
    "        perc_completed = 0 if status.request_counts.total == 0 else status.request_counts.completed / status.request_counts.total\n",
    "        print(f'waiting for batch: {batch_num}. Last status: {status.status}. progress={perc_completed:.1%}')\n",
    "        status = openAI.batches.retrieve(batch.id)\n",
    "    if status.status != \"completed\":\n",
    "        raise RuntimeError(f\"Batch ended as {status.status}: {status}\")\n",
    "    out_content = openAI.files.content(status.output_file_id).read().decode(\"utf-8\")\n",
    "    for line in out_content.strip().splitlines():\n",
    "        item = json.loads(line)\n",
    "        cid = item[\"custom_id\"]             # e.g., \"row-17\"\n",
    "        # The response payload lives at item[\"response\"][\"body\"]\n",
    "        body = item[\"response\"][\"body\"]\n",
    "        # Typical responses payloads put generated text at body[\"output\"][0][\"content\"][0][\"text\"]\n",
    "        # but use the exact shape you asked for:\n",
    "        unified_results[cid] = body\n",
    "unified_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fcc2a714-a792-4ef2-ab8f-5d27e76b4d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "status.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c041c5-5850-4ad4-954a-c093fea58461",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(\n",
    "    jobs['description'],\n",
    "    batch_size=32,\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "jobs['embedding'] = [emb.detach().cpu().numpy() for emb in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08182619-5320-485b-9517-2a047d2b7d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Senior Software Engineer, Applied AI\n",
      "Url: https://www.indeed.com/viewjob?jk=a53c64fadb77ee9b\n",
      "Title: Software Engineer - Analytics Platforms & Experiences (APX)\n",
      "Url: https://www.indeed.com/viewjob?jk=5693ba7970271f3f\n",
      "Title: Sr. Software Engineer II - StreamingTV\n",
      "Url: https://www.indeed.com/viewjob?jk=4d149be11348a3ef\n",
      "Title: Software Engineer - Fullstack\n",
      "Url: https://www.indeed.com/viewjob?jk=f75d0e7489b9c668\n",
      "Title: Developer Advocate, Developer Productivity, DevEx\n",
      "Url: https://www.indeed.com/viewjob?jk=da15865a44121cbd\n",
      "_______________\n",
      "Title: Sr Software Development Engineer\n",
      "Url: https://www.indeed.com/viewjob?jk=50ebc522b8d09ed9\n",
      "Title: Software Engineer (7300U) - Berkeley Seismological Lab\n",
      "Url: https://www.indeed.com/viewjob?jk=535907521ac63569\n",
      "Title: Senior Backend Engineer (Blockchain)\n",
      "Url: https://www.indeed.com/viewjob?jk=aabd8b03b8b760c7\n",
      "Title: Internship, Software Engineer, Factory Software (Winter/Spring 2026)\n",
      "Url: https://www.indeed.com/viewjob?jk=691aab2a0abc6c5c\n",
      "Title: Senior Software Security Compiler Engineer\n",
      "Url: https://www.indeed.com/viewjob?jk=210a85892aa32ea7\n",
      "***********************************\n",
      "Title: Software Engineer - API, Services and Backend Systems\n",
      "Url: https://www.indeed.com/viewjob?jk=a61128b0bf33926d\n",
      "Title: Senior Backend Engineer\n",
      "Url: https://www.indeed.com/viewjob?jk=60c857d039f9e5b6\n",
      "Title: Senior Software Engineer, Backend\n",
      "Url: https://www.indeed.com/viewjob?jk=8ce23d8b52c3aed9\n",
      "Title: Senior Software Engineer, Backend\n",
      "Url: https://www.indeed.com/viewjob?jk=bdc25e0e97b7be0e\n",
      "Title: Software Engineer II\n",
      "Url: https://www.indeed.com/viewjob?jk=07825fddc9c7e2e7\n",
      "_______________\n",
      "Title: Software Engineer, Full-Stack (5+ years of experience)\n",
      "Url: https://www.indeed.com/viewjob?jk=59ad81a84c77bded\n",
      "Title: Software Engineer, Full-Stack (8+ years of experience)\n",
      "Url: https://www.indeed.com/viewjob?jk=483ca1ff748f57a9\n",
      "Title: Software Engineer, Backend (5+ years of experience)\n",
      "Url: https://www.indeed.com/viewjob?jk=0148c4eae042863e\n",
      "Title: Software Engineer, Backend (8+ years of experience)\n",
      "Url: https://www.indeed.com/viewjob?jk=816cf3bd1f0c667e\n",
      "Title: Senior Staff Software Engineer\n",
      "Url: https://www.indeed.com/viewjob?jk=e7d480a5bb2a0d59\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "resume_embedding = model.encode(\n",
    "    resume_str,\n",
    "    batch_size=32,\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "fake_job_posting_embedding = model.encode(\n",
    "    fake_job_posting,\n",
    "    batch_size=32,\n",
    "    convert_to_tensor=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "def get_cos_sims(target_embedding):\n",
    "    cos_sims = [\n",
    "        F.cosine_similarity(\n",
    "            torch.tensor(embedding, dtype=torch.float32).unsqueeze(0),\n",
    "            target_embedding.unsqueeze(0)\n",
    "        ) for embedding in jobs['embedding']\n",
    "    ]\n",
    "    return [cos_sim[0].detach().cpu().numpy() for cos_sim in cos_sims]\n",
    "\n",
    "jobs['cos_sim_resume'] = get_cos_sims(resume_embedding)\n",
    "jobs['cos_sim_fake_job_posting'] = get_cos_sims(fake_job_posting_embedding)\n",
    "\n",
    "def sort_by_similarity_and_log(column_name):\n",
    "    sorted_jobs = jobs.sort_values(column_name, ascending=False)\n",
    "    most_similar = sorted_jobs.head()\n",
    "    # print(most_similar)\n",
    "    # print(most_similar.shape())\n",
    "    for closest in most_similar.itertuples(index=False):\n",
    "        print(f'Title: {closest.title}')\n",
    "        # print(f'Description: {closest.description}')\n",
    "        print(f'Url: {closest.job_url}')\n",
    "        # print(f'Similarity: {closest.cos_sim}')\n",
    "    print('_'*15)\n",
    "    most_disimilar = sorted_jobs.tail()\n",
    "    for closest in most_disimilar.itertuples(index=False):\n",
    "        print(f'Title: {closest.title}')\n",
    "        # print(f'Description: {closest.description}')\n",
    "        print(f'Url: {closest.job_url}')\n",
    "        # print(f'Similarity: {closest.cos_sim}')\n",
    "\n",
    "sort_by_similarity_and_log('cos_sim_resume')\n",
    "\n",
    "print('*'*35)\n",
    "\n",
    "sort_by_similarity_and_log('cos_sim_fake_job_posting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d3061-45f4-4b1e-b924-400e6ba78377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
